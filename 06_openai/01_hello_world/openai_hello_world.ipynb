{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019dc8b8",
   "metadata": {},
   "source": [
    "# **OpenAI Hello World**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "becc44c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from -r requirements.txt (line 1)) (1.96.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from -r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from tqdm>4->openai->-r requirements.txt (line 1)) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import find_dotenv, load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367e2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be9bfeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3732c84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê OpenAI Key Loaded: True\n"
     ]
    }
   ],
   "source": [
    "# Get the key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check and print whether it's loaded\n",
    "if api_key:\n",
    "    print(\"üîê OpenAI Key Loaded:\", bool(api_key))  # True or False\n",
    "if not api_key:\n",
    "    raise EnvironmentError(\"‚ùå OPENAI_API_KEY not found in .env file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5cb24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Send a simple message\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, world!\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e571c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BvHGXDmr4QfdMlcl9UQbIN4AtqiNl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1752990765, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=11, total_tokens=20, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "055ab7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Let's convert the API into a function\n",
    "\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt: str, model: str = \"gpt-3.5-turbo\") -> ChatCompletion:\n",
    "    \"\"\"\n",
    "    Sends a message to the OpenAI chat model and returns the full ChatCompletion response.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user's input message.\n",
    "        model (str): Which model to use (default is gpt-3.5-turbo).\n",
    "\n",
    "    Returns:\n",
    "        ChatCompletion: The full response object from OpenAI.\n",
    "    \"\"\"\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# üîç Test the function\n",
    "if __name__ == \"__main__\":\n",
    "    result = chat_completion(\"Hello, world!\")\n",
    "    print(result.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af92a611",
   "metadata": {},
   "source": [
    "#### **multiple roles in chat_completion api**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd20db21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world of social media strife,\n",
      "Where selfies reign and filters are life,\n",
      "I wish, oh how I wish it were true,\n",
      "That my camera could make me look as good as my profile, too!\n"
     ]
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def send_message(messages: list[dict], model: str = \"gpt-3.5-turbo\") -> ChatCompletion:\n",
    "    \"\"\"\n",
    "    Sends a list of messages to the OpenAI chat model and returns the full ChatCompletion response.\n",
    "\n",
    "    Args:\n",
    "        messages (list): List of message dicts with role/content (system, user, assistant).\n",
    "        model (str): The model to use.\n",
    "\n",
    "    Returns:\n",
    "        ChatCompletion: The full response object from OpenAI.\n",
    "    \"\"\"\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# üîç Test with multi-turn chat context\n",
    "if __name__ == \"__main__\":\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a professional english poet and humorist.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Mujhe ek funny english sher sunao.\"}\n",
    "    ]\n",
    "\n",
    "    result = send_message(messages)\n",
    "    print(result.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc909bf7",
   "metadata": {},
   "source": [
    "#### **Streaming Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f15b8f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Israel-Palestine dispute is a complex political and territorial issue that has spanned over several decades. It's rooted in claims over land, and intertwines with both religious and historical narratives. \n",
      "\n",
      "Historically, the issue began in the late 19th and early 20th century, as both Jews and Arab Muslims resided in the region known as Palestine, which was controlled by the Ottoman Empire, and later, by the British. Jews from Europe started moving towards Palestine in response to rising antisemitism, and in pursuit of their Zionist belief in a nation state for Jews. This led to tensions with Arab Palestinians.\n",
      "\n",
      "In 1947, in an effort to resolve the increasing pressure, the United Nations proposed a partition plan, which aimed to divide Palestine into two separate states, one for Jews and another for Arabs. The Jewish leaders accepted this plan, while the Arab leaders did not. \n",
      "\n",
      "This led to the 1948 Arab-Israeli war. Following the war, Israel established control over much of the land. Hundreds of thousands of Palestinians were displaced, generating a massive refugee issue that continues to this day. The territories‚ÄîWest Bank, Gaza Strip, and East Jerusalem‚Äîthat are not within the boundaries of Israel as established in 1948, are either occupied or controlled by Israel, which leads to the heart of the current conflict.\n",
      "\n",
      "Major issues that continue to fuel the conflict include disagreements on the status of refugees, Israel's occupation of the West Bank and control over Gaza, the construction of Israeli settlements in these territories, and the status of Jerusalem. Israel views Jerusalem as its undivided capital, while Palestinians envisage East Jerusalem as the capital of their future state.\n",
      "\n",
      "There are larger geopolitical considerations as well, with involvement from the United States, which has been historically supportive of Israel, and various Middle-Eastern countries that have supported Palestinians.\n",
      "\n",
      "Both sides have also seen the rise of more extreme voices that reject compromise, further complicating the negotiation process. Many peace initiatives, such as the Oslo Accords in 1993 or the Camp David Summit in 2000, have tried to resolve these issues but none has so far succeeded.\n",
      "\n",
      "This is a very simplified outline of what is an incredibly complex and sensitive issue, woven with historical injustices, ideological extremism, the horror of war, and a quest for self-determination from both sides. The human cost has been incredibly high and continues to impact not just Israel and Palestine, but also the wider Middle East and the world."
     ]
    }
   ],
   "source": [
    "from openai.types.chat import ChatCompletionChunk\n",
    "\n",
    "\n",
    "def stream_message(messages: list[dict], model: str = \"gpt-3.5-turbo\", max_tokens: int = 512) -> None:\n",
    "    \"\"\"\n",
    "    Streams a long response from OpenAI's chat model on a given message context.\n",
    "\n",
    "    Args:\n",
    "        messages (list): List of role-based messages.\n",
    "        model (str): Model name (gpt-3.5-turbo, gpt-4, etc.)\n",
    "        max_tokens (int): Max length of streamed output.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        stream=True \n",
    "    )\n",
    "\n",
    "    print(end=\" \", flush=True)\n",
    "    for chunk in response:\n",
    "        if isinstance(chunk, ChatCompletionChunk):\n",
    "            delta = chunk.choices[0].delta\n",
    "            content = delta.content or \"\"\n",
    "            print(content, end=\"\", flush=True)\n",
    "\n",
    "# üîç Streaming long opinion on Israel-Palestine issue\n",
    "if __name__ == \"__main__\":\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a political analyst who explains complex topics clearly and factually.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain the current Israel-Palestine issue neutrally and in detail.\"}\n",
    "    ]\n",
    "\n",
    "    stream_message(messages, max_tokens=512)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
