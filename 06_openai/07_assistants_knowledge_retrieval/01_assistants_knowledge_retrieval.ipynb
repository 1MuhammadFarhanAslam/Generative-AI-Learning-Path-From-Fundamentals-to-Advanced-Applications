{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd5e0fc",
   "metadata": {},
   "source": [
    "# **Assistants API: Knowledge Retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9973ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (1.97.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31a936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from -r requirements.txt (line 1)) (1.97.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from -r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from openai->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\farhanarain\\anaconda3\\envs\\streamlit\\lib\\site-packages (from tqdm>4->openai->-r requirements.txt (line 1)) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5096dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import find_dotenv, load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d7ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore only DeprecationWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09654753",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ea68c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê OpenAI Key Loaded: True\n"
     ]
    }
   ],
   "source": [
    "# Get the key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check and print whether it's loaded\n",
    "if api_key:\n",
    "    print(\"üîê OpenAI Key Loaded:\", bool(api_key))  # True or False\n",
    "if not api_key:\n",
    "    raise EnvironmentError(\"‚ùå OPENAI_API_KEY not found in .env file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f546831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9439ff",
   "metadata": {},
   "source": [
    "# **1. Create a new Assistant with File Search Enabled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b5fffb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_8iTCijvudm5Ks5nJdbQy76Bg',\n",
       " 'created_at': 1753086848,\n",
       " 'description': None,\n",
       " 'instructions': 'You are an expert in document search. You are required to retrieve information relative to user query when you find it suitable.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'name': 'Document Search Assistant',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'file_search',\n",
       "   'file_search': {'max_num_results': None,\n",
       "    'ranking_options': {'score_threshold': 0.0,\n",
       "     'ranker': 'default_2024_08_21'}}}],\n",
       " 'response_format': 'auto',\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {'code_interpreter': None,\n",
       "  'file_search': {'vector_store_ids': []}},\n",
       " 'top_p': 1.0,\n",
       " 'reasoning_effort': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Document Search Assistant\",\n",
    "  instructions=\"You are an expert in document search. You are required to retrieve information relative to user query when you find it suitable.\",\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1801a7a5",
   "metadata": {},
   "source": [
    "## **Upload files and add them to a Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e892b30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'vs_687dfb8140948191b5339bf141e90176',\n",
       " 'created_at': 1753086849,\n",
       " 'file_counts': {'cancelled': 0,\n",
       "  'completed': 0,\n",
       "  'failed': 0,\n",
       "  'in_progress': 0,\n",
       "  'total': 0},\n",
       " 'last_active_at': 1753086849,\n",
       " 'metadata': {},\n",
       " 'name': 'Document Search',\n",
       " 'object': 'vector_store',\n",
       " 'status': 'completed',\n",
       " 'usage_bytes': 0,\n",
       " 'expires_after': None,\n",
       " 'expires_at': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'vsfb_ac96aa39e6204ef39230b75869452fa3',\n",
       " 'created_at': 1753086852,\n",
       " 'file_counts': {'cancelled': 0,\n",
       "  'completed': 1,\n",
       "  'failed': 0,\n",
       "  'in_progress': 0,\n",
       "  'total': 1},\n",
       " 'object': 'vector_store.file_batch',\n",
       " 'status': 'completed',\n",
       " 'vector_store_id': 'vs_687dfb8140948191b5339bf141e90176'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a vector store caled \"Document Search\"\n",
    "vector_store = client.vector_stores.create(name=\"Document Search\")\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"zia_profile.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)\n",
    "\n",
    "show_json(vector_store)\n",
    "show_json(file_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c9638",
   "metadata": {},
   "source": [
    "## **Update the assistant to use the new Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbb08f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_8iTCijvudm5Ks5nJdbQy76Bg',\n",
       " 'created_at': 1753086848,\n",
       " 'description': None,\n",
       " 'instructions': 'You are an expert in document search. You are required to retrieve information relative to user query when you find it suitable.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'name': 'Document Search Assistant',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'file_search',\n",
       "   'file_search': {'max_num_results': None,\n",
       "    'ranking_options': {'score_threshold': 0.0,\n",
       "     'ranker': 'default_2024_08_21'}}}],\n",
       " 'response_format': 'auto',\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {'code_interpreter': None,\n",
       "  'file_search': {'vector_store_ids': ['vs_687dfb8140948191b5339bf141e90176']}},\n",
       " 'top_p': 1.0,\n",
       " 'reasoning_effort': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")\n",
    "\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86235366",
   "metadata": {},
   "source": [
    "## **Create a thread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "180c271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_687dfb8815448191b4c3925c7ea9922b'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'file-MHqBp7qshRiaXStnsk72HP',\n",
       " 'bytes': 48802,\n",
       " 'created_at': 1753086854,\n",
       " 'filename': 'zia_profile.pdf',\n",
       " 'object': 'file',\n",
       " 'purpose': 'assistants',\n",
       " 'status': 'processed',\n",
       " 'expires_at': None,\n",
       " 'status_details': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_HvR08t9o45HYlKsLjFxyxgaS',\n",
       " 'created_at': 1753086855,\n",
       " 'metadata': {},\n",
       " 'object': 'thread',\n",
       " 'tool_resources': {'code_interpreter': None,\n",
       "  'file_search': {'vector_store_ids': ['vs_687dfb8815448191b4c3925c7ea9922b']}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(\"zia_profile.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What are the qualifications of Zia Khan?\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)\n",
    "\n",
    "show_json(message_file)\n",
    "show_json(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0988d802",
   "metadata": {},
   "source": [
    "## **Create a run and check the output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c5ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > file_search\n",
      "\n",
      "\n",
      "assistant > Zia Khan holds a Master's in Economics from Karachi, and triple master's degrees (MBA, MS, and MAC) from Arizona State University (ASU). He is also a Certified Public Accountant (CPA) and a Certified Management Accountant (CMA) in the USA  .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "\n",
    "# Then, we use the stream SDK helper\n",
    "# with the EventHandler class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=None,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e3ca5",
   "metadata": {},
   "source": [
    "You're correct, and here's a clarified explanation based on the [OpenAI Assistants documentation for File Search](https://platform.openai.com/docs/assistants/tools/file-search):\n",
    "\n",
    "---\n",
    "\n",
    "##### **File Access Scope in OpenAI Assistants**\n",
    "\n",
    "#### 1. **Thread-Level File Uploads (User uploads during a thread)**\n",
    "\n",
    "* **Access Scope**: **Private to that user and thread**.\n",
    "* **Use Case**: When a user uploads a file during a conversation (thread), it is only available **within that thread** and **for that specific user**.\n",
    "* **Example**: If User A uploads a PDF in their conversation, the assistant can access it **only in that thread** for **that user** ‚Äî it‚Äôs **not shared** with other users or assistants.\n",
    "\n",
    "##### 2. **Assistant-Level File Uploads**\n",
    "\n",
    "* **Access Scope**: **Shared across all users** of that assistant.\n",
    "* **Use Case**: Files uploaded and attached directly to the **assistant** (via the API or dashboard) are available to **every user** interacting with that assistant.\n",
    "* **Example**: If you upload a CSV or knowledge base file to an assistant via the OpenAI dashboard or API, **any user** talking to that assistant can use that file via file search.\n",
    "\n",
    "---\n",
    "\n",
    "##### Summary Table\n",
    "\n",
    "| Upload Method               | File Scope          | Accessible To                 |\n",
    "| --------------------------- | ------------------- | ----------------------------- |\n",
    "| User upload (in thread)     | **Thread-level**    | Only that user in that thread |\n",
    "| Assistant file (via API/UI) | **Assistant-level** | All users of the assistant    |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb965907",
   "metadata": {},
   "source": [
    "# **2. Create a new Assistant with File Search Enabled**\n",
    "\n",
    "##### **Important**: *When a user uplaod file at a thread level, it is only accessible to a particular user. When a user upload a file at assistant level, it is accessible to all users which can access that particular assistant.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87222835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_HuBIXlUPYmSwOYBdGWwYu96x',\n",
       " 'created_at': 1753086871,\n",
       " 'description': None,\n",
       " 'instructions': 'You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.At the end, list the source file name(s) you used.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'name': 'Financial Analyst Assistant',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'file_search',\n",
       "   'file_search': {'max_num_results': None,\n",
       "    'ranking_options': {'score_threshold': 0.0,\n",
       "     'ranker': 'default_2024_08_21'}}}],\n",
       " 'response_format': 'auto',\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {'code_interpreter': None,\n",
       "  'file_search': {'vector_store_ids': []}},\n",
       " 'top_p': 1.0,\n",
       " 'reasoning_effort': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Financial Analyst Assistant\",\n",
    "  instructions=\"You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.\"\n",
    "    \"At the end, list the source file name(s) you used.\",\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c5063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_687dfb9ab00c8191aeef44ee627071e3'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'file-9PRz4ptpPv6VSsAg5UzqRU',\n",
       " 'bytes': 1453278,\n",
       " 'created_at': 1753086873,\n",
       " 'filename': 'Blue-Finance.pdf',\n",
       " 'object': 'file',\n",
       " 'purpose': 'assistants',\n",
       " 'status': 'processed',\n",
       " 'expires_at': None,\n",
       " 'status_details': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_Axgfhq8AonevkxVtjYli9RsU',\n",
       " 'created_at': 1753086874,\n",
       " 'metadata': {},\n",
       " 'object': 'thread',\n",
       " 'tool_resources': {'code_interpreter': None,\n",
       "  'file_search': {'vector_store_ids': ['vs_687dfb9ab00c8191aeef44ee627071e3']}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload the user provided file to OpenAI (It will be only accssible to a particular user)\n",
    "message_file = client.files.create(\n",
    "  file=open(\"Blue-Finance.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Based on the document, the concept of blue finance gained momentum in tenure of which pakistani Prime minister and what is the GMP of pakistan?\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)\n",
    "\n",
    "show_json(message_file)\n",
    "show_json(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed2cdfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > file_search\n",
      "\n",
      "\n",
      "assistant > The concept of blue finance gained momentum in Pakistan during the tenure of the former Prime Minister, Imran Khan, who declared 2020 as the year of the blue economy in Pakistan  . \n",
      "\n",
      "As for the Gross Domestic Product (GDP) of Pakistan, the document mentions that the blue economy of Pakistan currently contributes an estimated US$ 1 billion or around 0.4% of the national GDP .\n",
      "\n",
      "The information was found in the document \"Policy Brief Blue Finance: What is it and why does it matter for Pakistan?\" .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "\n",
    "# Then, we use the stream SDK helper\n",
    "# with the EventHandler class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=None,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
